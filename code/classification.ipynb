{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e561a8",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602df0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "df = pd.read_csv(\"./Relevant dataset/ae_to_soc_cluster.csv\", dtype=str)\n",
    "df[\"ae_text\"] = df[\"Adverse Events\"].astype(str).str.strip().str.lower().fillna(\"\")\n",
    "df[\"label\"]   = df[\"SOC Cluster\"].astype(str).str.strip().str.lower().fillna(\"\")\n",
    "\n",
    "label_counts  = df[\"label\"].value_counts()\n",
    "rare_labels   = label_counts[label_counts < 10].index.tolist()\n",
    "df[\"label_merged\"] = df[\"label\"].apply(lambda x: \"others\" if x in rare_labels else x)\n",
    "print(df[\"label_merged\"].value_counts())\n",
    "\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def get_embeddings(texts, tokenizer, model, device, max_length=128):\n",
    "    hidden_size = model.config.hidden_size\n",
    "    embs = []\n",
    "    with torch.no_grad():\n",
    "        for txt in texts:\n",
    "            if not txt:\n",
    "                embs.append(np.zeros(hidden_size, dtype=float))\n",
    "                continue\n",
    "            inputs = tokenizer(\n",
    "                txt, return_tensors=\"pt\",\n",
    "                truncation=True, padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k,v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            cls_vec = outputs.last_hidden_state[:,0,:].squeeze().cpu().numpy()\n",
    "            embs.append(cls_vec)\n",
    "    return np.vstack(embs)\n",
    "\n",
    "print(\" Encoding text with BioBERT...\")\n",
    "X = get_embeddings(df[\"ae_text\"].tolist(), tokenizer, model, device)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y  = le.fit_transform(df[\"label_merged\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": (\n",
    "        RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        {'n_estimators': [200,300], 'max_depth':[10,20,30], 'min_samples_split':[2,5,8]}\n",
    "    ),\n",
    "    \"Logistic Regression\": (\n",
    "        LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "        {'C':[1,10,20], 'solver':['liblinear','lbfgs']}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "        {'n_estimators':[100,200,300], 'max_depth':[3,6,9], 'learning_rate':[0.01,0.1]}\n",
    "    )\n",
    "}\n",
    "\n",
    "metrics_summary = {}\n",
    "fitted_clfs     = {}\n",
    "\n",
    "for name, (clf, param_grid) in models.items():\n",
    "    print(f\"\\n===== Model: {name} =====\")\n",
    "    gs = GridSearchCV(\n",
    "        clf, param_grid,\n",
    "        cv=5, scoring=\"f1_macro\",\n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_clf    = gs.best_estimator_\n",
    "    fitted_clfs[name] = best_clf\n",
    "    print(\" Best params:\", gs.best_params_)\n",
    "\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "    acc    = accuracy_score(y_test, y_pred)\n",
    "    f1m    = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    prec   = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    rec    = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    labels_test = unique_labels(y_test, y_pred)\n",
    "    print(classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=labels_test,\n",
    "        target_names=le.inverse_transform(labels_test)\n",
    "    ))\n",
    "\n",
    "    metrics_summary[name] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Macro\": f1m\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba60ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_summary).T\n",
    "\n",
    "metrics_vis = metrics_df[[\"Precision\", \"Recall\", \"F1 Macro\"]]\n",
    "\n",
    "\n",
    "metrics_long = (\n",
    "    metrics_vis\n",
    "    .reset_index()\n",
    "    .melt(id_vars=\"index\", var_name=\"Metric\", value_name=\"Score\")\n",
    "    .rename(columns={\"index\": \"Model\"})\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.barplot(\n",
    "    data=metrics_long,\n",
    "    x=\"Metric\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Model\",\n",
    "    palette=\"Set2\"  \n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    h = p.get_height()\n",
    "    ax.annotate(\n",
    "        f\"{h:.2f}\",\n",
    "        (p.get_x() + p.get_width() / 2, h + 0.01),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Model Comparison on Precision / Recall / F1\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Score\", fontsize=12)\n",
    "ax.set_xlabel(\"\")\n",
    "plt.legend(title=\"Model\", fontsize=11, title_fontsize=12, loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7247ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_name = max(metrics_summary, key=lambda k: metrics_summary[k][\"F1 Macro\"])\n",
    "best_clf  = fitted_clfs[best_name]\n",
    "y_pred_b  = best_clf.predict(X_test)\n",
    "\n",
    "cm     = confusion_matrix(y_test, y_pred_b)\n",
    "labels = le.inverse_transform(unique_labels(y_test, y_pred_b))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "disp.plot(\n",
    "    ax=ax,\n",
    "    cmap=\"Blues\",\n",
    "    colorbar=False,       \n",
    "    include_values=True,\n",
    "    xticks_rotation=90,\n",
    "    values_format=\"d\",\n",
    "    im_kw={\"aspect\": \"equal\"}\n",
    ")\n",
    "\n",
    "im   = disp.im_\n",
    "cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label(\"Count\", rotation=270, labelpad=15, fontsize=12)\n",
    "\n",
    "ax.set_title(f\"Confusion Matrix â€” Best Model: {best_name}\", fontsize=16, fontweight=\"bold\", pad=20)\n",
    "ax.set_xlabel(\"Predicted Label\", fontsize=14, labelpad=12)\n",
    "ax.set_ylabel(\"True Label\", fontsize=14, labelpad=12)\n",
    "ax.tick_params(axis=\"x\", labelsize=8, labelrotation=90)\n",
    "ax.tick_params(axis=\"y\", labelsize=8, labelrotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1651426",
   "metadata": {},
   "source": [
    "# External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "external_df = pd.read_csv(\"./Relevant dateset/Evaludate dateset.csv.csv\", dtype=str)\n",
    "external_df = external_df.dropna(subset=[\"SOC Cluster\"])\n",
    "external_df[\"ae_text\"] = external_df[\"Adverse Event\"].astype(str).str.lower().str.strip()\n",
    "external_df[\"label\"]   = external_df[\"SOC Cluster\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "external_df[\"label_merged\"] = external_df[\"label\"].apply(\n",
    "    lambda x: \"others\" if x in rare_labels else x\n",
    ")\n",
    "\n",
    "external_df = external_df[external_df[\"label_merged\"].isin(le.classes_)].reset_index(drop=True)\n",
    "\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model     = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def get_embeddings(texts, tokenizer, model, device, max_length=128):\n",
    "    hidden_size = model.config.hidden_size\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for txt in texts:\n",
    "            if not txt:\n",
    "                embeddings.append(np.zeros(hidden_size))\n",
    "                continue\n",
    "            inputs = tokenizer(txt, return_tensors=\"pt\", truncation=True,\n",
    "                               padding=\"max_length\", max_length=max_length)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            cls_vec = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "            embeddings.append(cls_vec)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "print(\"Encoding external data with BioBERT...\")\n",
    "X_ext = get_embeddings(external_df[\"ae_text\"].tolist(), tokenizer, model, device)\n",
    "\n",
    "y_ext = le.transform(external_df[\"label_merged\"])\n",
    "\n",
    "y_pred_ext = best_clf.predict(X_ext)\n",
    "\n",
    "labels_ext = unique_labels(y_ext, y_pred_ext)\n",
    "print(\"\\ External Evaluation Report:\")\n",
    "print(classification_report(\n",
    "    y_ext, y_pred_ext,\n",
    "    labels=labels_ext,\n",
    "    target_names=le.inverse_transform(labels_ext)\n",
    "))\n",
    "\n",
    "acc_ext  = accuracy_score(y_ext, y_pred_ext)\n",
    "f1_ext   = f1_score(y_ext, y_pred_ext, average=\"macro\")\n",
    "prec_ext = precision_score(y_ext, y_pred_ext, average=\"macro\")\n",
    "rec_ext  = recall_score(y_ext, y_pred_ext, average=\"macro\")\n",
    "\n",
    "print(f\"\\n  External Accuracy:  {acc_ext:.4f}\")\n",
    "print(f\"  External F1 Macro:  {f1_ext:.4f}\")\n",
    "print(f\"  External Precision: {prec_ext:.4f}\")\n",
    "print(f\"  External Recall:    {rec_ext:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the DataFrame with external validation metrics\n",
    "metrics = {\n",
    "    \"Metric\": [\"External Accuracy\", \"External F1 Macro\", \"External Precision\", \"External Recall\"],\n",
    "    \"Value\": [0.8354, 0.8250, 0.8332, 0.8257]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Prepare your metrics\n",
    "metrics = {\n",
    "    \"Metric\": [\n",
    "        \"External Accuracy\",\n",
    "        \"External F1 Macro\",\n",
    "        \"External Precision\",\n",
    "        \"External Recall\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        0.8354,\n",
    "        0.8250,\n",
    "        0.8332,\n",
    "        0.8257\n",
    "    ]\n",
    "}\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "\n",
    "# 2. Plot as a table\n",
    "fig, ax = plt.subplots(figsize=(6, 2))\n",
    "ax.axis(\"off\")  # no axes\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(\n",
    "    cellText=df_metrics.values,\n",
    "    colLabels=df_metrics.columns,\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\"\n",
    ")\n",
    "\n",
    "# Styling\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_ext, y_pred_ext, labels=labels_ext)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=le.inverse_transform(labels_ext),\n",
    "    yticklabels=le.inverse_transform(labels_ext)\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix â€” External Validation\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Biobert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
